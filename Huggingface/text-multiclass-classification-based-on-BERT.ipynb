{"cells":[{"cell_type":"markdown","metadata":{"id":"vWo1YQl2_Bt7"},"source":["# Text Multiclass Classification based on BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":737,"status":"ok","timestamp":1655906225706,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"qicOUuCzZs7f","outputId":"0894a9d6-65f8-4b0a-b0fd-762bff9fbb0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5531,"status":"ok","timestamp":1655906231233,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"CF9XAypcZ8Du","outputId":"79cce6d9-6079-4e62-f67e-c061878c342b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGPqcjcxZ-O9"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss # multi class loss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import AutoModel,AutoConfig,AutoTokenizer\n","from transformers import AutoModelForSequenceClassification, AdamW\n","from tqdm import tqdm, trange\n","from ast import literal_eval"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4482,"status":"ok","timestamp":1655906250418,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"L-4VvFX1aAHJ","outputId":"c5b4ba64-ada3-4706-9c17-d0cd8b0627f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n"]}],"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9984,"status":"ok","timestamp":1655906260380,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"-xu0vRiLaBbI","outputId":"74e47835-17f3-4bd7-e8bf-d1d32a495bda"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1655906260381,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"3h3lhGDfaCfu","outputId":"4af24fd9-5b62-470a-d5fb-b12c18200708"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"markdown","metadata":{"id":"1ClDma3PaDeb"},"source":["## Data Preprocessing\n","\n","The Jigsaw Toxic Comment dataset comes from [Kaggle](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/rules). The training set contains comments with their binary labels. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2055,"status":"ok","timestamp":1655906262426,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"_ViId5MeaFuO","outputId":"51bacc97-4717-4292-e924-b2148ac24db0"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-35649175-f77d-4c59-a42d-6647601074b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35649175-f77d-4c59-a42d-6647601074b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-35649175-f77d-4c59-a42d-6647601074b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-35649175-f77d-4c59-a42d-6647601074b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n","1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n","2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n","3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n","4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('./drive/MyDrive/Colab Notebooks/huggingface/datasets/toxic_tweet_data/train.csv') #jigsaw-toxic-comment-classification-challenge\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1655906262430,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"dIbxXqn3aHTZ","outputId":"b27dda02-266f-4f09-8398-397558d31bb5"},"outputs":[{"data":{"text/plain":["0    144277\n","1     15294\n","Name: toxic, dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['toxic'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1655906262848,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"CK_oh9v_aIw-","outputId":"6b70f513-2d91-4880-8469-c3548ad7b982"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique comments:  True\n","Null values:  False\n"]}],"source":["print('Unique comments: ', df.comment_text.nunique() == df.shape[0]) \n","print('Null values: ', df.isnull().values.any())\n","# df[df.isna().any(axis=1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134,"status":"ok","timestamp":1655906262979,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"Wu5VTL7ZaKyi","outputId":"22b23262-f30c-4b02-d9a9-40dc32fe46c3"},"outputs":[{"data":{"text/plain":["id               0\n","comment_text     0\n","toxic            0\n","severe_toxic     0\n","obscene          0\n","threat           0\n","insult           0\n","identity_hate    0\n","dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.shape[0]-df.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6011,"status":"ok","timestamp":1655906268985,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"lkHPimDnaKwB","outputId":"d1306e53-69a2-4212-e5db-717693e8c2ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["average sentence length:  67.27352714465661\n","stdev sentence length:  99.23070219290523\n"]}],"source":["print('average sentence length: ', df.comment_text.str.split().str.len().mean())\n","print('stdev sentence length: ', df.comment_text.str.split().str.len().std())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2408,"status":"ok","timestamp":1655906271830,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"lZUCvHg7aKtP","outputId":"34ec78a2-976c-4323-ed57-a4420c79eac5"},"outputs":[{"data":{"text/plain":["count    159571.000000\n","mean         67.273527\n","std          99.230702\n","min           1.000000\n","25%          17.000000\n","50%          36.000000\n","75%          75.000000\n","max        1411.000000\n","Name: comment_text, dtype: float64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.comment_text.str.split().str.len().describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1770,"status":"ok","timestamp":1655906273590,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"LOYgXYidaKqq","outputId":"b3d4b8ad-adaa-4be3-d67c-c5ca5bbc33d7"},"outputs":[{"data":{"text/plain":["10087"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["sum(df.comment_text.str.split().str.len()>200)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1655906273591,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"lgGG5RHkaKnh","outputId":"5fabbaf4-3251-457a-f6fd-0c1f5e4d82e8"},"outputs":[{"data":{"text/plain":["(159571, 8)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1655906273592,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"pywMQMDqaKlf","outputId":"d25d2caa-4797-4f0c-cf10-495c8676cd54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label columns:  ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"]}],"source":["cols = df.columns \n","label_cols = list(cols[2:]) # labels\n","num_labels = len(label_cols) # number of labels\n","print('Label columns: ', label_cols)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1655906273593,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"Y2ZWtREoaKiQ","outputId":"e798a024-aaaa-427d-83e8-d41eef52b09e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Count of 1 per label: \n"," toxic            15294\n","severe_toxic      1595\n","obscene           8449\n","threat             478\n","insult            7877\n","identity_hate     1405\n","dtype: int64 \n","\n","Count of 0 per label: \n"," toxic            144277\n","severe_toxic     157976\n","obscene          151122\n","threat           159093\n","insult           151694\n","identity_hate    158166\n","dtype: int64\n"]}],"source":["print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') \n","print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGMvf9mBaKgV"},"outputs":[],"source":["df = df.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1655906273958,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"f-u818ApaKc2","outputId":"08c9c460-5797-44c3-98dd-1806f600275d"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-941d756f-0fd4-4056-9749-f522dddc9715\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>one_hot_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2ae932b8fc3a999e</td>\n","      <td>Unspecified source for Image:Wof_pic.jpg\\n\\nTh...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4d489b38c78f8a21</td>\n","      <td>\"\\n\\nAfD nomination of Chris D. Jackson\\nChris...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8577f232edddfbc4</td>\n","      <td>Did he? \\n\\nIs there any evidence that he DIDN...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9164b36a625d8ddb</td>\n","      <td>OK! Let's just all agree that there is a disti...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>823bb316efd22c63</td>\n","      <td>Hmmmm, the Sandy strategy of maintaining good ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-941d756f-0fd4-4056-9749-f522dddc9715')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-941d756f-0fd4-4056-9749-f522dddc9715 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-941d756f-0fd4-4056-9749-f522dddc9715');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  2ae932b8fc3a999e  Unspecified source for Image:Wof_pic.jpg\\n\\nTh...      0   \n","1  4d489b38c78f8a21  \"\\n\\nAfD nomination of Chris D. Jackson\\nChris...      0   \n","2  8577f232edddfbc4  Did he? \\n\\nIs there any evidence that he DIDN...      0   \n","3  9164b36a625d8ddb  OK! Let's just all agree that there is a disti...      0   \n","4  823bb316efd22c63  Hmmmm, the Sandy strategy of maintaining good ...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate      one_hot_labels  \n","0             0        0       0       0              0  [0, 0, 0, 0, 0, 0]  \n","1             0        0       0       0              0  [0, 0, 0, 0, 0, 0]  \n","2             0        0       0       0              0  [0, 0, 0, 0, 0, 0]  \n","3             0        0       0       0              0  [0, 0, 0, 0, 0, 0]  \n","4             0        0       0       0              0  [0, 0, 0, 0, 0, 0]  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df['one_hot_labels'] = list(df[label_cols].values) # one hot encode labels\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45714,"status":"ok","timestamp":1655906319662,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"ui1NlZYxeEd6","outputId":"c7c5b698-757e-4415-8e09-6a5a7c682f18"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer lowercases\n","def token_len(sen):\n","  tokens = tokenizer.encode(sen, max_length = 300)\n","  return len(tokens)\n","\n","df['len'] = df['comment_text'].map(token_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1655906319783,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"-tZDVItsexfB","outputId":"c1b813dd-d14c-411b-e81e-c4ca41f2e9db"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-0ef4d75f-a3ff-4d76-8814-9953bf6d2bdf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>one_hot_labels</th>\n","      <th>len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>8577f232edddfbc4</td>\n","      <td>Did he? \\n\\nIs there any evidence that he DIDN...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>823bb316efd22c63</td>\n","      <td>Hmmmm, the Sandy strategy of maintaining good ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>841da71419b5863a</td>\n","      <td>He should have been in BFDI as Ice cube \\n\\nSa...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>00163c0c893b488f</td>\n","      <td>Do not blank your page\\nAgainst Wiki rules!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>16a157f0041ea30c</td>\n","      <td>Make the page of chance and real \\n\\nplease190...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>78140</th>\n","      <td>159559</td>\n","      <td>c8336e578bab9ee1</td>\n","      <td>Feel free to include that within the article! ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>78141</th>\n","      <td>159561</td>\n","      <td>a0ed388bade78646</td>\n","      <td>Okay I think I fixed what Anma was complaining...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>78142</th>\n","      <td>159565</td>\n","      <td>ea811baaf7f222bd</td>\n","      <td>and Crime in the Dominican Republic</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>78143</th>\n","      <td>159567</td>\n","      <td>7785f845381fc85d</td>\n","      <td>December 2007 (UTC)\\n\\nCan't say we didn't war...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>78144</th>\n","      <td>159568</td>\n","      <td>0a7ae9a68d0d924a</td>\n","      <td>Nonsense. And this is coming from one of the k...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>78145 rows Ã— 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ef4d75f-a3ff-4d76-8814-9953bf6d2bdf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ef4d75f-a3ff-4d76-8814-9953bf6d2bdf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ef4d75f-a3ff-4d76-8814-9953bf6d2bdf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        index                id  \\\n","0           2  8577f232edddfbc4   \n","1           4  823bb316efd22c63   \n","2           5  841da71419b5863a   \n","3           6  00163c0c893b488f   \n","4           7  16a157f0041ea30c   \n","...       ...               ...   \n","78140  159559  c8336e578bab9ee1   \n","78141  159561  a0ed388bade78646   \n","78142  159565  ea811baaf7f222bd   \n","78143  159567  7785f845381fc85d   \n","78144  159568  0a7ae9a68d0d924a   \n","\n","                                            comment_text  toxic  severe_toxic  \\\n","0      Did he? \\n\\nIs there any evidence that he DIDN...      0             0   \n","1      Hmmmm, the Sandy strategy of maintaining good ...      0             0   \n","2      He should have been in BFDI as Ice cube \\n\\nSa...      0             0   \n","3            Do not blank your page\\nAgainst Wiki rules!      0             0   \n","4      Make the page of chance and real \\n\\nplease190...      0             0   \n","...                                                  ...    ...           ...   \n","78140  Feel free to include that within the article! ...      0             0   \n","78141  Okay I think I fixed what Anma was complaining...      0             0   \n","78142                and Crime in the Dominican Republic      0             0   \n","78143  December 2007 (UTC)\\n\\nCan't say we didn't war...      0             0   \n","78144  Nonsense. And this is coming from one of the k...      0             0   \n","\n","       obscene  threat  insult  identity_hate      one_hot_labels  len  \n","0            0       0       0              0  [0, 0, 0, 0, 0, 0]   40  \n","1            0       0       0              0  [0, 0, 0, 0, 0, 0]   31  \n","2            0       0       0              0  [0, 0, 0, 0, 0, 0]   14  \n","3            0       0       0              0  [0, 0, 0, 0, 0, 0]   12  \n","4            0       0       0              0  [0, 0, 0, 0, 0, 0]   18  \n","...        ...     ...     ...            ...                 ...  ...  \n","78140        0       0       0              0  [0, 0, 0, 0, 0, 0]   15  \n","78141        0       0       0              0  [0, 0, 0, 0, 0, 0]   29  \n","78142        0       0       0              0  [0, 0, 0, 0, 0, 0]    8  \n","78143        0       0       0              0  [0, 0, 0, 0, 0, 0]   30  \n","78144        0       0       0              0  [0, 0, 0, 0, 0, 0]   21  \n","\n","[78145 rows x 11 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df_select = df.iloc[np.where(df['len'] <= 50)].reset_index()\n","df_select"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1655906319785,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"7DBg43n3kHTR","outputId":"a5e44742-1a25-4b7e-bd68-4c87ec1a5275"},"outputs":[{"name":"stdout","output_type":"stream","text":["Count of 1 per label: \n"," toxic            9828\n","severe_toxic     1123\n","obscene          5648\n","threat            322\n","insult           5283\n","identity_hate     935\n","dtype: int64 \n","\n","Count of 0 per label: \n"," toxic            68317\n","severe_toxic     77022\n","obscene          72497\n","threat           77823\n","insult           72862\n","identity_hate    77210\n","dtype: int64\n"]}],"source":["print('Count of 1 per label: \\n', df_select[label_cols].sum(), '\\n') \n","print('Count of 0 per label: \\n', df_select[label_cols].eq(0).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYURLZpOaKaZ"},"outputs":[],"source":["labels = list(df_select.one_hot_labels.values)\n","comments = list(df_select.comment_text.values)"]},{"cell_type":"markdown","metadata":{"id":"FdKyHQy-af8H"},"source":["## Tokenization\n","\n","Use per-trained BERT tokenizer to tokenize sentences into tokens, specify the max number of tokens in each sentence. \n","\n","\n","BERT:  \n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)   \n","\n","XLNet:  \n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False)   \n","\n","RoBERTa:  \n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8811,"status":"ok","timestamp":1655906328589,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"0BNoc6eSaH_8","outputId":"e2a67137-decc-45dd-c652-e4f2fa48d987"},"outputs":[{"data":{"text/plain":["50"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["train_length = []\n","for comm in comments:\n","  tokens = tokenizer.encode(comm, max_length=300)\n","  train_length.append(len(tokens))\n","\n","max(train_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"elapsed":771,"status":"ok","timestamp":1655906329348,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"NWnUEqO-aPG-","outputId":"56015500-cdda-472a-ddfc-d161eade02aa"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","sns.distplot(train_length)\n","plt.xlim([0, 60]);\n","plt.xlabel('Token count');"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7026,"status":"ok","timestamp":1655906336360,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"XXtxAmDuaKXr","outputId":"cb00ade5-b600-462d-d7cc-6d84681db6bf"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"name":"stdout","output_type":"stream","text":["tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"]}],"source":["max_length = 50\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer lowercases\n","encodings = tokenizer.batch_encode_plus(\n","    comments,\n","    max_length=max_length,\n","    pad_to_max_length=True\n",") # tokenizer's encoding method\n","print('tokenizer outputs: ', encodings.keys()) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Zc-fVXOaoEu"},"outputs":[],"source":["input_ids = encodings['input_ids'] # tokenized and encoded sentences\n","token_type_ids = encodings['token_type_ids'] # token type ids\n","attention_masks = encodings['attention_mask'] # attention masks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1655906336365,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"E5cP4VfZaqW8","outputId":"b0e734e1-4e2c-4c66-db92-d0309ce1c193"},"outputs":[{"data":{"text/plain":["[101,\n"," 2106,\n"," 2002,\n"," 1029,\n"," 2003,\n"," 2045,\n"," 2151,\n"," 3350,\n"," 2008,\n"," 2002,\n"," 2134,\n"," 1005,\n"," 1056,\n"," 3102,\n"," 1996,\n"," 1046,\n"," 24316,\n"," 1010,\n"," 2672,\n"," 1996,\n"," 2030,\n"," 23773,\n"," 2389,\n"," 8543,\n"," 2001,\n"," 3031,\n"," 2242,\n"," 2044,\n"," 2035,\n"," 1012,\n"," 2023,\n"," 2035,\n"," 3504,\n"," 2200,\n"," 26489,\n"," 6292,\n"," 2000,\n"," 2033,\n"," 1012,\n"," 102,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["input_ids[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1655906336366,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"CcryHPu9asPt","outputId":"4d5a2258-9916-42f9-8301-0f2a846d19c9"},"outputs":[{"data":{"text/plain":["['[CLS]',\n"," 'did',\n"," 'he',\n"," '?',\n"," 'is',\n"," 'there',\n"," 'any',\n"," 'evidence',\n"," 'that',\n"," 'he',\n"," 'didn',\n"," \"'\",\n"," 't',\n"," 'kill',\n"," 'the',\n"," 'j',\n"," '##fk',\n"," ',',\n"," 'maybe',\n"," 'the',\n"," 'or',\n"," '##ign',\n"," '##al',\n"," 'creator',\n"," 'was',\n"," 'onto',\n"," 'something',\n"," 'after',\n"," 'all',\n"," '.',\n"," 'this',\n"," 'all',\n"," 'looks',\n"," 'very',\n"," 'dod',\n"," '##gy',\n"," 'to',\n"," 'me',\n"," '.',\n"," '[SEP]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.convert_ids_to_tokens(input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1655906336527,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"Vt7oSfdVbEGO","outputId":"8efa2235-41b7-4452-977c-246ed5b5f006"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Did he? \\n\\nIs there any evidence that he DIDN'T kill the JFK, maybe the orignal creator was onto something after all. This all looks very dodgy to me.\""]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["comments[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5782,"status":"ok","timestamp":1655906342295,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"P8E-xc1abFoy","outputId":"c74cc3a7-e3a6-4027-f1a3-1aa0e3a8d697"},"outputs":[{"name":"stdout","output_type":"stream","text":["df label indices with only one instance:  [50826]\n"]}],"source":["label_counts = df_select.one_hot_labels.astype(str).value_counts()\n","one_freq = label_counts[label_counts==1].keys()\n","one_freq_idxs = sorted(list(df_select[df_select.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n","print('df label indices with only one instance: ', one_freq_idxs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zanfehoScZSY"},"outputs":[],"source":["# Gathering single instance inputs to force into the training set after stratified split\n","one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n","one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n","one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n","one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"]},{"cell_type":"markdown","metadata":{"id":"6XQ3OVcycivJ"},"source":["## Construct Dataloader\n","\n","Split dataset into training and validation set, and then construct the dataloader with pre-specified batch size.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1753,"status":"ok","timestamp":1655906344030,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"_qSwCNaXcf6-","outputId":"3cf037ef-eaaf-4b31-8f67-a631b68f975b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  # This is added back by InteractiveShellApp.init_path()\n"]}],"source":["# Split dataset\n","train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids, attention_masks,random_state=2020, test_size=0.20, stratify = labels)\n","\n","# Add one frequency data to train data\n","train_inputs.extend(one_freq_input_ids)\n","train_labels.extend(one_freq_labels)\n","train_masks.extend(one_freq_attention_masks)\n","train_token_types.extend(one_freq_token_types)\n","\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","train_token_types = torch.tensor(train_token_types)\n","\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","validation_token_types = torch.tensor(validation_token_types)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tB_nXb1Wc0wd"},"outputs":[],"source":["# 8 16 32 64  128 256\n","batch_size = 128\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n","train_sampler = RandomSampler(train_data) # \n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n","validation_sampler = SequentialSampler(validation_data) \n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Rxwtz2Dc3q1"},"outputs":[],"source":["torch.save(validation_dataloader,'./drive/MyDrive/Colab Notebooks/huggingface/datasets/toxic_tweet_data/validation_data_loader')\n","torch.save(train_dataloader,'./drive/MyDrive/Colab Notebooks/huggingface/datasets/toxic_tweet_data/train_data_loader')"]},{"cell_type":"markdown","metadata":{"id":"ngmjHYWxc6Gg"},"source":["## Build Model \n","\n","Model Configuration:\n","\n","AutoModel:  \n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)  \n","\n","BERT:  \n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)  \n","\n","XLNet:  \n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)  \n","\n","RoBERTa:  \n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2172,"status":"ok","timestamp":1655906346571,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"MF9BvPvJdBZe","outputId":"350e56d1-c9e2-40fa-afac-4a0484ba7824"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels) \n","# num_labelsï¼š6 \n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1afJZVeVdOu7"},"outputs":[],"source":["paras=[para for para in model.named_parameters()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_71ObFAdTwm"},"outputs":[],"source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1655906346574,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"F7kTSfumdVSZ","outputId":"65c64b5f-8aeb-4237-bff0-a4daa0981fc3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n","# 1e-5,2e-5,5e-5\n","# optimizer = AdamW(model.parameters(),lr=2e-5) "]},{"cell_type":"markdown","metadata":{"id":"uJBpSp7MdWe9"},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2565539,"status":"ok","timestamp":1655908912100,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"Uti6toKDdX6H","outputId":"d5926372-6cf7-4b5b-881d-33de9d37f661"},"outputs":[{"name":"stderr","output_type":"stream","text":["\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0\n","Step: 0\n","Step: 10\n","Step: 20\n","Step: 30\n","Step: 40\n","Step: 50\n","Step: 60\n","Step: 70\n","Step: 80\n","Step: 90\n","Step: 100\n","Step: 110\n","Step: 120\n","Step: 130\n","Step: 140\n","Step: 150\n","Step: 160\n","Step: 170\n","Step: 180\n","Step: 190\n","Step: 200\n","Step: 210\n","Step: 220\n","Step: 230\n","Step: 240\n","Step: 250\n","Step: 260\n","Step: 270\n","Step: 280\n","Step: 290\n","Step: 300\n","Step: 310\n","Step: 320\n","Step: 330\n","Step: 340\n","Step: 350\n","Step: 360\n","Step: 370\n","Step: 380\n","Step: 390\n","Step: 400\n","Step: 410\n","Step: 420\n","Step: 430\n","Step: 440\n","Step: 450\n","Step: 460\n","Step: 470\n","Step: 480\n","Train loss: 0.1085205231021884\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch:  20%|â–ˆâ–ˆ        | 1/5 [08:32<34:11, 512.76s/it]"]},{"name":"stdout","output_type":"stream","text":["F1 Validation Accuracy:  79.50700280112045\n","Flat Validation Accuracy:  90.79915541621345\n","Epoch: 1\n","Step: 0\n","Step: 10\n","Step: 20\n","Step: 30\n","Step: 40\n","Step: 50\n","Step: 60\n","Step: 70\n","Step: 80\n","Step: 90\n","Step: 100\n","Step: 110\n","Step: 120\n","Step: 130\n","Step: 140\n","Step: 150\n","Step: 160\n","Step: 170\n","Step: 180\n","Step: 190\n","Step: 200\n","Step: 210\n","Step: 220\n","Step: 230\n","Step: 240\n","Step: 250\n","Step: 260\n","Step: 270\n","Step: 280\n","Step: 290\n","Step: 300\n","Step: 310\n","Step: 320\n","Step: 330\n","Step: 340\n","Step: 350\n","Step: 360\n","Step: 370\n","Step: 380\n","Step: 390\n","Step: 400\n","Step: 410\n","Step: 420\n","Step: 430\n","Step: 440\n","Step: 450\n","Step: 460\n","Step: 470\n","Step: 480\n","Train loss: 0.04886388534523836\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [17:06<25:39, 513.07s/it]"]},{"name":"stdout","output_type":"stream","text":["F1 Validation Accuracy:  81.16624040920716\n","Flat Validation Accuracy:  90.44724550515069\n","Epoch: 2\n","Step: 0\n","Step: 10\n","Step: 20\n","Step: 30\n","Step: 40\n","Step: 50\n","Step: 60\n","Step: 70\n","Step: 80\n","Step: 90\n","Step: 100\n","Step: 110\n","Step: 120\n","Step: 130\n","Step: 140\n","Step: 150\n","Step: 160\n","Step: 170\n","Step: 180\n","Step: 190\n","Step: 200\n","Step: 210\n","Step: 220\n","Step: 230\n","Step: 240\n","Step: 250\n","Step: 260\n","Step: 270\n","Step: 280\n","Step: 290\n","Step: 300\n","Step: 310\n","Step: 320\n","Step: 330\n","Step: 340\n","Step: 350\n","Step: 360\n","Step: 370\n","Step: 380\n","Step: 390\n","Step: 400\n","Step: 410\n","Step: 420\n","Step: 430\n","Step: 440\n","Step: 450\n","Step: 460\n","Step: 470\n","Step: 480\n","Train loss: 0.038616274845365485\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [25:39<17:06, 513.14s/it]"]},{"name":"stdout","output_type":"stream","text":["F1 Validation Accuracy:  81.28869765977541\n","Flat Validation Accuracy:  90.66478981380767\n","Epoch: 3\n","Step: 0\n","Step: 10\n","Step: 20\n","Step: 30\n","Step: 40\n","Step: 50\n","Step: 60\n","Step: 70\n","Step: 80\n","Step: 90\n","Step: 100\n","Step: 110\n","Step: 120\n","Step: 130\n","Step: 140\n","Step: 150\n","Step: 160\n","Step: 170\n","Step: 180\n","Step: 190\n","Step: 200\n","Step: 210\n","Step: 220\n","Step: 230\n","Step: 240\n","Step: 250\n","Step: 260\n","Step: 270\n","Step: 280\n","Step: 290\n","Step: 300\n","Step: 310\n","Step: 320\n","Step: 330\n","Step: 340\n","Step: 350\n","Step: 360\n","Step: 370\n","Step: 380\n","Step: 390\n","Step: 400\n","Step: 410\n","Step: 420\n","Step: 430\n","Step: 440\n","Step: 450\n","Step: 460\n","Step: 470\n","Step: 480\n","Train loss: 0.031849963462898215\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [34:12<08:33, 513.11s/it]"]},{"name":"stdout","output_type":"stream","text":["F1 Validation Accuracy:  82.22480702125411\n","Flat Validation Accuracy:  91.2022522234308\n","Epoch: 4\n","Step: 0\n","Step: 10\n","Step: 20\n","Step: 30\n","Step: 40\n","Step: 50\n","Step: 60\n","Step: 70\n","Step: 80\n","Step: 90\n","Step: 100\n","Step: 110\n","Step: 120\n","Step: 130\n","Step: 140\n","Step: 150\n","Step: 160\n","Step: 170\n","Step: 180\n","Step: 190\n","Step: 200\n","Step: 210\n","Step: 220\n","Step: 230\n","Step: 240\n","Step: 250\n","Step: 260\n","Step: 270\n","Step: 280\n","Step: 290\n","Step: 300\n","Step: 310\n","Step: 320\n","Step: 330\n","Step: 340\n","Step: 350\n","Step: 360\n","Step: 370\n","Step: 380\n","Step: 390\n","Step: 400\n","Step: 410\n","Step: 420\n","Step: 430\n","Step: 440\n","Step: 450\n","Step: 460\n","Step: 470\n","Step: 480\n","Train loss: 0.02653844808637791\n"]},{"name":"stderr","output_type":"stream","text":["Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [42:45<00:00, 513.08s/it]"]},{"name":"stdout","output_type":"stream","text":["F1 Validation Accuracy:  81.65271966527197\n","Flat Validation Accuracy:  90.82474886429074\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 5\n","\n","# trange is a tqdm wrapper around the normal python range\n","for ep_ in trange(epochs, desc=\"Epoch\"):\n","  print(f\"Epoch: {ep_}\")\n","\n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  model.train() \n","\n","  # Tracking variables\n","  tr_loss = 0 #running loss\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    \n","    if step % 10 == 0:\n","      print(f\"Step: {step}\")\n","\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    # \n","    # train_inputs.extend(one_freq_input_ids)\n","    # train_labels.extend(one_freq_labels)\n","    # train_masks.extend(one_freq_attention_masks)\n","    # train_token_types.extend(one_freq_token_types)\n","    # \n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","\n","    # # Forward pass for multiclass classification\n","    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    # loss = outputs[0]\n","    # logits = outputs[1]\n","\n","    # Forward pass for multilabel classification\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    \n","    loss_func = BCEWithLogitsLoss() \n","    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","    # loss_func = BCELoss() \n","    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","    train_loss_set.append(loss.item()) # record loss    \n","\n","    # Backward pass\n","    loss.backward() \n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    # scheduler.step()\n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","###############################################################################\n","\n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  model.eval()\n","\n","  # Variables to gather full output\n","  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","  # Predict\n","  for i, batch in enumerate(validation_dataloader):\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    with torch.no_grad():\n","      # Forward pass\n","      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      b_logit_pred = outs[0]\n","      pred_label = torch.sigmoid(b_logit_pred)\n","\n","      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","      pred_label = pred_label.to('cpu').numpy()\n","      b_labels = b_labels.to('cpu').numpy()\n","\n","    tokenized_texts.append(b_input_ids)\n","    logit_preds.append(b_logit_pred)\n","    true_labels.append(b_labels)\n","    pred_labels.append(pred_label)\n","\n","  # Flatten outputs\n","  pred_labels = [item for sublist in pred_labels for item in sublist]\n","  true_labels = [item for sublist in true_labels for item in sublist]\n","\n","  # \n","  threshold = 0.50\n","  pred_bools = [pl>threshold for pl in pred_labels]\n","  true_bools = [tl==1 for tl in true_labels]\n","  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n","  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n","\n","  print('F1 Validation Accuracy: ', val_f1_accuracy)\n","  print('Flat Validation Accuracy: ', val_flat_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJbA_pV9d1zr"},"outputs":[],"source":["torch.save(model.state_dict(), './drive/MyDrive/Colab Notebooks/huggingface/bert_model_toxic')"]},{"cell_type":"markdown","metadata":{"id":"xnJl4B_Fd6jp"},"source":["## Prepare Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":1217,"status":"ok","timestamp":1655908915046,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"qYRYsTkkd3Y4","outputId":"a3c11da4-0ac4-4f73-a3fc-2ab62142277e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Null values:  False\n","Same columns between train and test:  True\n"]},{"data":{"text/html":["\n","  <div id=\"df-9fb6383a-66f0-48ac-83c5-96daf9e39e17\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00001cee341fdb12</td>\n","      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0000247867823ef7</td>\n","      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00013b17ad220c46</td>\n","      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00017563c3f7919a</td>\n","      <td>:If you have a look back at the source, the in...</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00017695ad8997eb</td>\n","      <td>I don't anonymously edit articles at all.</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fb6383a-66f0-48ac-83c5-96daf9e39e17')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9fb6383a-66f0-48ac-83c5-96daf9e39e17 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9fb6383a-66f0-48ac-83c5-96daf9e39e17');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...     -1   \n","1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...     -1   \n","2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...     -1   \n","3  00017563c3f7919a  :If you have a look back at the source, the in...     -1   \n","4  00017695ad8997eb          I don't anonymously edit articles at all.     -1   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0            -1       -1      -1      -1             -1  \n","1            -1       -1      -1      -1             -1  \n","2            -1       -1      -1      -1             -1  \n","3            -1       -1      -1      -1             -1  \n","4            -1       -1      -1      -1             -1  "]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["test_df = pd.read_csv('./drive/MyDrive/Colab Notebooks/huggingface/datasets/toxic_tweet_data/test.csv')\n","test_labels_df = pd.read_csv('./drive/MyDrive/Colab Notebooks/huggingface/datasets/toxic_tweet_data/test_labels.csv')\n","test_df = test_df.merge(test_labels_df, on='id', how='left')\n","test_label_cols = list(test_df.columns[2:])\n","print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n","print('Same columns between train and test: ', label_cols == test_label_cols) #columns should be the same\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1655908915047,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"6YoS6ekGeIMv","outputId":"3a5227cf-abc8-45cd-b44c-b63336de0746"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-5b7822c6-07c3-439d-8ec1-0b4eb4e0d57d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>one_hot_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>0001ea8717f6de06</td>\n","      <td>Thank you for understanding. I think very high...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>000247e83dcc1211</td>\n","      <td>:Dear god this site is horrible.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0002f87b16116a7f</td>\n","      <td>\"::: Somebody will invariably try to add Relig...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0003e1cccfd5a40a</td>\n","      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>00059ace3e3e9a53</td>\n","      <td>\" \\n\\n == Before adding a new product to the l...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b7822c6-07c3-439d-8ec1-0b4eb4e0d57d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5b7822c6-07c3-439d-8ec1-0b4eb4e0d57d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5b7822c6-07c3-439d-8ec1-0b4eb4e0d57d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                  id                                       comment_text  \\\n","5   0001ea8717f6de06  Thank you for understanding. I think very high...   \n","7   000247e83dcc1211                   :Dear god this site is horrible.   \n","11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...   \n","13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...   \n","14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...   \n","\n","    toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n","5       0             0        0       0       0              0   \n","7       0             0        0       0       0              0   \n","11      0             0        0       0       0              0   \n","13      0             0        0       0       0              0   \n","14      0             0        0       0       0              0   \n","\n","        one_hot_labels  \n","5   [0, 0, 0, 0, 0, 0]  \n","7   [0, 0, 0, 0, 0, 0]  \n","11  [0, 0, 0, 0, 0, 0]  \n","13  [0, 0, 0, 0, 0, 0]  \n","14  [0, 0, 0, 0, 0, 0]  "]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/comments with -1 values\n","test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KVnwZIseLlv"},"outputs":[],"source":["# Gathering input data\n","test_labels = list(test_df.one_hot_labels.values)\n","test_comments = list(test_df.comment_text.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15646,"status":"ok","timestamp":1655908930813,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"HrS4c1tPeNZa","outputId":"55d3dbf7-1dc0-4c30-df11-ef1d8a763fae"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["test_encodings = tokenizer.batch_encode_plus(test_comments,max_length=max_length,pad_to_max_length=True)\n","test_input_ids = test_encodings['input_ids']\n","test_token_type_ids = test_encodings['token_type_ids']\n","test_attention_masks = test_encodings['attention_mask']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_thyMrmVeP4z"},"outputs":[],"source":["# Make tensors out of data\n","test_inputs = torch.tensor(test_input_ids)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(test_attention_masks)\n","test_token_types = torch.tensor(test_token_type_ids)\n","# Create test dataloader\n","test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","# Save test dataloader\n","torch.save(test_dataloader,'./drive/MyDrive/Colab Notebooks/huggingface/datasets/toxic_tweet_data/test_data_loader')"]},{"cell_type":"markdown","metadata":{"id":"TKE3E5YpeRAZ"},"source":["## Evaluation and Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kELgDPFJeSVC"},"outputs":[],"source":["# Test\n","\n","# Put model in evaluation mode to evaluate loss on the validation set\n","model.eval()\n","\n","# track variables\n","logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","# Predict\n","for i, batch in enumerate(test_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","  with torch.no_grad():\n","    # Forward pass\n","    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    b_logit_pred = outs[0]\n","    pred_label = torch.sigmoid(b_logit_pred)\n","\n","    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","    pred_label = pred_label.to('cpu').numpy()\n","    b_labels = b_labels.to('cpu').numpy()\n","\n","  tokenized_texts.append(b_input_ids)\n","  logit_preds.append(b_logit_pred)\n","  true_labels.append(b_labels)\n","  pred_labels.append(pred_label)\n","\n","# Flatten outputs\n","tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n","pred_labels = [item for sublist in pred_labels for item in sublist]\n","true_labels = [item for sublist in true_labels for item in sublist]\n","# Converting flattened binary values to boolean values\n","true_bools = [tl==1 for tl in true_labels]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":522,"status":"ok","timestamp":1655909108818,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"sLvb0t9ueU1H","outputId":"2f24eaac-412a-4f5f-c094-07e607c3995e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test F1 Accuracy:  0.6537698697864267\n","Test Flat Accuracy:  0.8694082340804652 \n","\n","               precision    recall  f1-score   support\n","\n","        toxic       0.53      0.86      0.66      6090\n"," severe_toxic       0.32      0.59      0.41       367\n","      obscene       0.57      0.81      0.67      3691\n","       threat       0.55      0.48      0.52       211\n","       insult       0.66      0.71      0.68      3427\n","identity_hate       0.66      0.53      0.58       712\n","\n","    micro avg       0.56      0.78      0.65     14498\n","    macro avg       0.55      0.66      0.59     14498\n"," weighted avg       0.57      0.78      0.65     14498\n","  samples avg       0.07      0.07      0.07     14498\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n","\n","# Print and save classification report\n","print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n","print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n","clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n","pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n","print(clf_report)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1655909108819,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"3_Sn6s2zeae-","outputId":"4adb5835-4f4e-4ef8-d4ea-5c06ff836c10"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 'toxic', 1: 'severe_toxic', 2: 'obscene', 3: 'threat', 4: 'insult', 5: 'identity_hate'}\n"]}],"source":["idx2label = dict(zip(range(6),label_cols))\n","print(idx2label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tiAfK0xNebw0"},"outputs":[],"source":["# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n","true_label_idxs, pred_label_idxs=[],[]\n","for vals in true_bools:\n","  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n","for vals in pred_bools:\n","  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lmxj_saWedRJ"},"outputs":[],"source":["# Gathering vectors of label names using idx2label\n","true_label_texts, pred_label_texts = [], []\n","for vals in true_label_idxs:\n","  if vals:\n","    true_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    true_label_texts.append(vals)\n","\n","for vals in pred_label_idxs:\n","  if vals:\n","    pred_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    pred_label_texts.append(vals)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUoaIcK2eere"},"outputs":[],"source":["# Decoding input ids to comment text\n","comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1655909114324,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"c5QgzuhwegFC","outputId":"bfd055f6-cc6f-48e8-da69-43d474d2720f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ce64593a-12de-4959-9502-6bd0ace54e0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>true_labels</th>\n","      <th>pred_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>thank you for understanding. i think very high...</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>: dear god this site is horrible.</td>\n","      <td>[]</td>\n","      <td>[toxic]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\" : : : somebody will invariably try to add re...</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\" it says it right there that it is a type. th...</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\" = = before adding a new product to the list,...</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce64593a-12de-4959-9502-6bd0ace54e0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ce64593a-12de-4959-9502-6bd0ace54e0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ce64593a-12de-4959-9502-6bd0ace54e0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                        comment_text true_labels pred_labels\n","0  thank you for understanding. i think very high...          []          []\n","1                  : dear god this site is horrible.          []     [toxic]\n","2  \" : : : somebody will invariably try to add re...          []          []\n","3  \" it says it right there that it is a type. th...          []          []\n","4  \" = = before adding a new product to the list,...          []          []"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Converting lists to df\n","comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n","comparisons_df.to_csv('comparisons.csv')\n","comparisons_df.head()"]},{"cell_type":"markdown","metadata":{"id":"W66o--oUek3a"},"source":["### F1 score threshold search\n","\n","\n","You should optimize your model for recall if you want to decrease the number of false negatives. You should optimize your model for precision when you want to decrease the number of false positives.\n","\n","F1 score is calculated by taking the harmonic mean of precision and recall and ranges from 0 to 1. Harmonic mean has a nice arithmetic property representing a truly balanced mean. If either precision or recall is low, it suffers significantly.\n","\n","\"If you have a high class imbalance, always choose the F1 score because a high F1 score considers both precision and recall.\" To get a high F1, both false positives and false negatives must be low. \n","\n","Reference:\n","\n","https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd\n","\n","https://stats.stackexchange.com/questions/71700/how-to-draw-roc-curve-with-three-response-variable\n","\n","https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1655909114324,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"487NCcPIeoXX","outputId":"69907d68-804d-4f4f-df6e-2f4bc4a29b47"},"outputs":[{"data":{"text/plain":["array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["macro_thresholds = np.array(range(1,10))/10\n","macro_thresholds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7020,"status":"ok","timestamp":1655909121340,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"},"user_tz":240},"id":"PsFabfHqeq8r","outputId":"be247be3-9f4d-47f5-f64e-f4529af79d5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Threshold:  0.73\n","Test F1 Accuracy:  0.6644462947543713\n","Test Flat Accuracy:  0.8837256556941449 \n","\n","               precision    recall  f1-score   support\n","\n","        toxic       0.58      0.83      0.68      6090\n"," severe_toxic       0.46      0.22      0.30       367\n","      obscene       0.62      0.77      0.69      3691\n","       threat       0.72      0.22      0.33       211\n","       insult       0.74      0.61      0.67      3427\n","identity_hate       0.76      0.41      0.53       712\n","\n","    micro avg       0.62      0.72      0.66     14498\n","    macro avg       0.65      0.51      0.53     14498\n"," weighted avg       0.63      0.72      0.66     14498\n","  samples avg       0.07      0.07      0.07     14498\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["f1_results, flat_acc_results = [], []\n","for th in macro_thresholds:\n","  pred_bools = [pl>th for pl in pred_labels]\n","  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n","  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","  f1_results.append(test_f1_accuracy)\n","  flat_acc_results.append(test_flat_accuracy)\n","\n","best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n","\n","micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n","\n","f1_results, flat_acc_results = [], []\n","for th in micro_thresholds:\n","  pred_bools = [pl>th for pl in pred_labels]\n","  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n","  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","  f1_results.append(test_f1_accuracy)\n","  flat_acc_results.append(test_flat_accuracy)\n","\n","best_f1_idx = np.argmax(f1_results) #best threshold value\n","\n","# Printing and saving classification report\n","print('Best Threshold: ', micro_thresholds[best_f1_idx])\n","print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n","print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n","\n","best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n","clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n","pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n","print(clf_report_optimized)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPXLwr1GBQU/vyNwJfWDe27","collapsed_sections":[],"name":"text-multiclass-classification-based-on-BERT.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
