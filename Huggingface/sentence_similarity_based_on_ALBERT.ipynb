{"cells":[{"cell_type":"markdown","metadata":{"id":"EyDp_qlcscMO"},"source":["# Sentence Similarity Identification based on ALBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5oaYmrbscMS","executionInfo":{"status":"ok","timestamp":1656625599732,"user_tz":240,"elapsed":3406,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"790ac181-577c-4868-a95f-c38d4acd32f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.3.2)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAU4PncLs6GA","executionInfo":{"status":"ok","timestamp":1656625604705,"user_tz":240,"elapsed":4979,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"8000d311-c5d6-4b59-de91-7d021a000c0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRnzwD1LscMV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import os\n","import matplotlib.pyplot as plt\n","import copy\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset\n","from torch.cuda.amp import autocast, GradScaler\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n","from datasets import load_dataset, load_metric\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"DZ4JcnaqscMX"},"source":["## Load Data\n","\n","The General Language Understanding Evaluation (GLUE) benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems. The Microsoft Research Paraphrase Corpus (MRPC) subset of GLUE dataset is a corpus of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["742da9b0dd26490e91b27e234784c77a","68fc3aa37c38417e821e5e633a244ac3","46e1dd1e01c641e59b545946d759885d","f325bd1f03ca4545ac031c3f50370563","1bc35f10619c430da108631f91bcdc8b","03b2d1f0399342719faa298e7a500b47","3e0ffedca8f04bbd89f15372e98fb143","1deb50f9dc244b578af5c507e9e769b9","0e07731151324d09b4e36767b7e91de8","9b25dfd2a3b34899908b3e4c1a6db450","212d3949b34d4429a38ea5d70d6179c7"]},"id":"17acVcN8scMX","executionInfo":{"status":"ok","timestamp":1656625605866,"user_tz":240,"elapsed":1166,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"d9d9f54c-c442-4f9d-ca78-856fcc263206"},"outputs":[{"output_type":"stream","name":"stderr","text":["Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"742da9b0dd26490e91b27e234784c77a"}},"metadata":{}}],"source":["dataset = load_dataset('glue', 'mrpc')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEPRq6s3scMZ"},"outputs":[],"source":["# dataset['train'].to_pandas().to_csv('train.csv',index=None)\n","# dataset['test'].to_pandas().to_csv('test.csv',index=None)\n","# dataset['validation'].to_pandas().to_csv('validation.csv',index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBvCVHIYscMa"},"outputs":[],"source":["df_train = dataset['train'].to_pandas()\n","df_val = dataset['test'].to_pandas()\n","df_test = dataset['validation'].to_pandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaTi6Rg6scMc","executionInfo":{"status":"ok","timestamp":1656625605868,"user_tz":240,"elapsed":16,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"6b6d04f9-072c-4699-e7c8-163f06f21d1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(3668, 4)\n","(1725, 4)\n","(408, 4)\n"]}],"source":["print(df_train.shape)\n","print(df_val.shape)\n","print(df_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"c5gXIV2wscMd","executionInfo":{"status":"ok","timestamp":1656625605869,"user_tz":240,"elapsed":15,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"9e6c1a00-279c-4d97-d84a-e2edbf4bc9db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           sentence1  \\\n","0  Amrozi accused his brother , whom he called \" ...   \n","1  Yucaipa owned Dominick 's before selling the c...   \n","2  They had published an advertisement on the Int...   \n","3  Around 0335 GMT , Tab shares were up 19 cents ...   \n","4  The stock rose $ 2.11 , or about 11 percent , ...   \n","\n","                                           sentence2  label  idx  \n","0  Referring to him as only \" the witness \" , Amr...      1    0  \n","1  Yucaipa bought Dominick 's in 1995 for $ 693 m...      0    1  \n","2  On June 10 , the ship 's owners had published ...      1    2  \n","3  Tab shares jumped 20 cents , or 4.6 % , to set...      0    3  \n","4  PG & E Corp. shares jumped $ 1.63 or 8 percent...      1    4  "],"text/html":["\n","  <div id=\"df-fc06fe82-5434-4f3d-8ba4-7e0d57ed2042\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence1</th>\n","      <th>sentence2</th>\n","      <th>label</th>\n","      <th>idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Amrozi accused his brother , whom he called \" ...</td>\n","      <td>Referring to him as only \" the witness \" , Amr...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yucaipa owned Dominick 's before selling the c...</td>\n","      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>They had published an advertisement on the Int...</td>\n","      <td>On June 10 , the ship 's owners had published ...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n","      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n","      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc06fe82-5434-4f3d-8ba4-7e0d57ed2042')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc06fe82-5434-4f3d-8ba4-7e0d57ed2042 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc06fe82-5434-4f3d-8ba4-7e0d57ed2042');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}],"source":["df_train.head()"]},{"cell_type":"markdown","metadata":{"id":"NaRc3INNscMf"},"source":["## Define Dataset and Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGYJOqz9scMg"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    \n","    def __init__(self, data, maxlen, with_labels=True, bert_model='albert-base-v2'):\n","\n","        self.data = data  # pandas dataframe\n","        # Initialize the tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  \n","\n","        self.maxlen = maxlen\n","        self.with_labels = with_labels \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        # Get sentence 1 and sentence 2\n","        sent1 = str(self.data.loc[index, 'sentence1'])\n","        sent2 = str(self.data.loc[index, 'sentence2'])\n","\n","        # Tokenize sentences to get input_ids, attention_mask, token_type_ids\n","        encoded_pair = self.tokenizer(sent1, sent2,\n","                                      padding='max_length',\n","                                      truncation=True,\n","                                      max_length=self.maxlen,  \n","                                      return_tensors='pt')\n","        \n","        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor token ids\n","        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # padded values \"0\"，other token \"1\"\n","        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # the first sentence is 0，teh second sentence is 1 # single sentence is 0\n","\n","        if self.with_labels:  # true if the dataset has labels\n","            label = self.data.loc[index, 'label']\n","            return token_ids, attn_masks, token_type_ids, label  \n","        else:\n","            return token_ids, attn_masks, token_type_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3qvkbaPscMi"},"outputs":[],"source":["class SentencePairClassifier(nn.Module):\n","    \n","    def __init__(self, bert_model=\"albert-base-v2\", freeze_bert=False):\n","        super(SentencePairClassifier, self).__init__()\n","        #  Initialize Bert model\n","        self.bert_layer = AutoModel.from_pretrained(bert_model)\n","\n","        #  Encoder hidden size\n","        if bert_model == \"albert-base-v2\":  # 12M parameter\n","            hidden_size = 768\n","        elif bert_model == \"albert-large-v2\":  # 18M parameter\n","            hidden_size = 1024\n","        elif bert_model == \"albert-xlarge-v2\":  # 60M parameter\n","            hidden_size = 2048\n","        elif bert_model == \"albert-xxlarge-v2\":  # 235M parameter\n","            hidden_size = 4096\n","        elif bert_model == \"bert-base-uncased\": # 110M parameter\n","            hidden_size = 768\n","        elif bert_model == \"roberta-base\": # \n","            hidden_size = 768\n","\n","        # Freeze Bert layer, udpate output layer\n","        if freeze_bert:\n","            for p in self.bert_layer.parameters():\n","                p.requires_grad = False\n","                \n","        self.dropout = nn.Dropout(p=0.1)\n","        # Output\n","        self.cls_layer = nn.Linear(hidden_size, 1)\n","\n","\n","    @autocast()\n","    def forward(self, input_ids, attn_masks, token_type_ids):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor containing token ids\n","            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n","            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n","        '''\n","\n","        outputs = self.bert_layer(input_ids, attn_masks, token_type_ids)\n","        logits = self.cls_layer(self.dropout(outputs['pooler_output']))\n","\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gT2D741jscMj"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\" \n","    set random seed to make sure reproducibility\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","\n","def evaluate_loss(net, device, criterion, dataloader):\n","    \"\"\"\n","    evaluation\n","    \"\"\"\n","    net.eval()\n","\n","    mean_loss = 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n","            count += 1\n","\n","    return mean_loss / count"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQDINSESscMk","executionInfo":{"status":"ok","timestamp":1656625605872,"user_tz":240,"elapsed":16,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"cb09f7de-184c-47fb-866c-83a6959c4020"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create /models:\n","mkdir: cannot create directory ‘models’: File exists\n"]}],"source":["print(\"Create /models:\")\n","!mkdir models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvz8fzTtscMl"},"outputs":[],"source":["def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n","\n","    best_loss = np.Inf\n","    best_ep = 1\n","    nb_iterations = len(train_loader)\n","    print_every = nb_iterations // 5\n","    iters = []\n","    train_losses = []\n","    val_losses = []\n","\n","    scaler = GradScaler()\n","\n","    for ep in range(epochs):\n","\n","        net.train()\n","        running_loss = 0.0\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n","\n","            # To cuda tensor\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","    \n","            # Training\n","            with autocast():\n","                # Obtaining the logits from the model\n","                logits = net(seq, attn_masks, token_type_ids)\n","\n","                # Computing loss\n","                loss = criterion(logits.squeeze(-1), labels.float())\n","                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n","\n","            # Backpropagating the gradients\n","            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n","            scaler.scale(loss).backward()\n","\n","            if (it + 1) % iters_to_accumulate == 0:\n","                # Optimization step\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n","                # otherwise, opti.step() is skipped.\n","                scaler.step(opti)\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","                # Learning rate scheduler\n","                lr_scheduler.step()\n","                # Zero grads\n","                opti.zero_grad()\n","\n","            running_loss += loss.item()\n","\n","            if (it + 1) % print_every == 0:  # Print training loss information\n","                print()\n","                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n","                      .format(it+1, nb_iterations, ep+1, running_loss / print_every))\n","\n","                running_loss = 0.0\n","\n","        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n","        print()\n","        print(\"Epoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n","\n","        if val_loss < best_loss:\n","            print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n","            print()\n","            net_copy = copy.deepcopy(net)  # save the best\n","            best_loss = val_loss\n","            best_ep = ep + 1\n","\n","    # Save model\n","    path_to_model='models/{}_lr_{}_val_loss_{}_ep_{}.pt'.format(bert_model, lr, round(best_loss, 5), best_ep)\n","    torch.save(net_copy.state_dict(), path_to_model)\n","    print(\"The model has been saved in {}\".format(path_to_model))\n","\n","    del loss\n","    torch.cuda.empty_cache() # clear cache"]},{"cell_type":"markdown","metadata":{"id":"pRbB15ZZscMm"},"source":["Set hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ToR1OThqscMm"},"outputs":[],"source":["bert_model = \"albert-base-v2\"  # 'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2', 'albert-xxlarge-v2', 'bert-base-uncased', ...\n","freeze_bert = False\n","maxlen = 128\n","bs = 16\n","iters_to_accumulate = 2\n","lr = 2e-5\n","epochs = 4"]},{"cell_type":"markdown","metadata":{"id":"hUyeOWcnscMn"},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d80VlirgscMn","executionInfo":{"status":"ok","timestamp":1656625788777,"user_tz":240,"elapsed":182371,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"42a87ac7-a8ce-4912-b2ef-205ecd447802"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading training data...\n","Reading validation data...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias']\n","- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"," 20%|██        | 47/230 [00:08<00:30,  5.99it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 46/230 of epoch 1 complete. Loss : 0.3061587499535602 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 92/230 [00:16<00:25,  5.40it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 92/230 of epoch 1 complete. Loss : 0.2999498432745104 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 139/230 [00:24<00:14,  6.26it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 138/230 of epoch 1 complete. Loss : 0.28176639002302417 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 185/230 [00:31<00:07,  6.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 184/230 of epoch 1 complete. Loss : 0.23857205555490826 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 230/230 [00:39<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 230/230 of epoch 1 complete. Loss : 0.1963310355077619 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108/108 [00:06<00:00, 15.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 complete! Validation Loss : 0.42950938476456535\n","Best validation loss improved from inf to 0.42950938476456535\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 47/230 [00:07<00:29,  6.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 46/230 of epoch 2 complete. Loss : 0.21621850489274316 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 93/230 [00:14<00:21,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 92/230 of epoch 2 complete. Loss : 0.1833103133932404 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 139/230 [00:22<00:14,  6.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 138/230 of epoch 2 complete. Loss : 0.16331993318770244 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 185/230 [00:29<00:07,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 184/230 of epoch 2 complete. Loss : 0.1508555891316222 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 230/230 [00:36<00:00,  6.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 230/230 of epoch 2 complete. Loss : 0.10634245249726203 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108/108 [00:06<00:00, 15.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2 complete! Validation Loss : 0.3831238277532436\n","Best validation loss improved from 0.42950938476456535 to 0.3831238277532436\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 47/230 [00:07<00:28,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 46/230 of epoch 3 complete. Loss : 0.13440796708607156 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 93/230 [00:14<00:21,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 92/230 of epoch 3 complete. Loss : 0.1131011993502793 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 139/230 [00:22<00:14,  6.27it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 138/230 of epoch 3 complete. Loss : 0.0839476099278292 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 185/230 [00:29<00:07,  6.23it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 184/230 of epoch 3 complete. Loss : 0.10391206545350344 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 230/230 [00:36<00:00,  6.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 230/230 of epoch 3 complete. Loss : 0.06701752614310902 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108/108 [00:06<00:00, 15.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3 complete! Validation Loss : 0.3760102068384488\n","Best validation loss improved from 0.3831238277532436 to 0.3760102068384488\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 47/230 [00:07<00:29,  6.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 46/230 of epoch 4 complete. Loss : 0.08687805910797222 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 93/230 [00:14<00:21,  6.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 92/230 of epoch 4 complete. Loss : 0.04968400489862846 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 139/230 [00:22<00:14,  6.31it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 138/230 of epoch 4 complete. Loss : 0.040833380022693586 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 185/230 [00:29<00:07,  6.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 184/230 of epoch 4 complete. Loss : 0.05276209719317115 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 230/230 [00:36<00:00,  6.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 230/230 of epoch 4 complete. Loss : 0.03645308971728967 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108/108 [00:06<00:00, 15.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4 complete! Validation Loss : 0.3938129919546622\n","The model has been saved in models/albert-base-v2_lr_2e-05_val_loss_0.37601_ep_3.pt\n"]}],"source":["# Set seed\n","set_seed(1)\n","\n","# Create training set and validation set\n","print(\"Reading training data...\")\n","train_set = CustomDataset(df_train, maxlen, bert_model)\n","print(\"Reading validation data...\")\n","val_set = CustomDataset(df_val, maxlen, bert_model)\n","\n","# DataLoader\n","train_loader = DataLoader(train_set, batch_size=bs, num_workers=0)\n","val_loader = DataLoader(val_set, batch_size=bs, num_workers=0)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = SentencePairClassifier(bert_model, freeze_bert=freeze_bert)\n","\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    net = nn.DataParallel(net)\n","\n","net.to(device)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","num_training_steps = epochs * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * epochs  # Necessary to take into account Gradient accumulation\n","lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","\n","train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)"]},{"cell_type":"markdown","metadata":{"id":"ubyZwLBYscMo"},"source":["## Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uZecuCescMo","executionInfo":{"status":"ok","timestamp":1656625789108,"user_tz":240,"elapsed":348,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"f335ad65-97fb-4fb3-e2f1-94098030edbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creation of the results' folder...\n","mkdir: cannot create directory ‘results’: File exists\n"]}],"source":["print(\"Creation of the results' folder...\")\n","!mkdir results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eHjnxBG0scMp"},"outputs":[],"source":["def get_probs_from_logits(logits):\n","    \"\"\"\n","    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n","    \"\"\"\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    return probs.detach().cpu().numpy()\n","\n","def test_prediction(net, device, dataloader, with_labels=True, result_file=\"results/output.txt\"):\n","    \"\"\"\n","    Predict the probabilities on a dataset with or without labels and print the result in a file\n","    \"\"\"\n","    net.eval()\n","    w = open(result_file, 'w')\n","    probs_all = []\n","\n","    with torch.no_grad():\n","        if with_labels:\n","            for seq, attn_masks, token_type_ids, _ in tqdm(dataloader):# 训练集、验证集\n","                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","                logits = net(seq, attn_masks, token_type_ids)\n","                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","                probs_all += probs.tolist()\n","        else:\n","            for seq, attn_masks, token_type_ids in tqdm(dataloader): # 没有标签的测试集\n","                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","                logits = net(seq, attn_masks, token_type_ids)\n","                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","                probs_all += probs.tolist()\n","\n","    w.writelines(str(prob)+'\\n' for prob in probs_all)\n","    w.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQqgQ8B6scMq","executionInfo":{"status":"ok","timestamp":1656625851191,"user_tz":240,"elapsed":5288,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"45a5e5ce-4285-441b-e22c-ec037e604f1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading test data...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias']\n","- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n","Loading the weights of the model...\n","Predicting on test data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26/26 [00:01<00:00, 15.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Predictions are available in : results/output.txt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["path_to_model = 'models/albert-base-v2_lr_2e-05_val_loss_0.37601_ep_3.pt'\n","\n","# path_to_model = '/content/models/...'  # customized trained model\n","\n","path_to_output_file = 'results/output.txt'\n","\n","print(\"Reading test data...\")\n","test_set = CustomDataset(df_test, maxlen, bert_model)\n","test_loader = DataLoader(test_set, batch_size=bs, num_workers=0)\n","\n","model = SentencePairClassifier(bert_model)\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    model = nn.DataParallel(model)\n","\n","print()\n","print(\"Loading the weights of the model...\")\n","model.load_state_dict(torch.load(path_to_model))\n","model.to(device)\n","\n","print(\"Predicting on test data...\")\n","test_prediction(net=model, device=device, \n","                dataloader=test_loader, with_labels=True,  # set the with_labels parameter to False if your want to get predictions on a dataset without labels\n","                result_file=path_to_output_file)\n","print()\n","print(\"Predictions are available in : {}\".format(path_to_output_file))"]},{"cell_type":"markdown","metadata":{"id":"MDMCmk8AscMr"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZThhUxjscMr"},"outputs":[],"source":["path_to_output_file = 'results/output.txt'\n","\n","labels_test = df_test['label'] # true labels\n","\n","probs_test = pd.read_csv(path_to_output_file, header=None)[0]\n","threshold = 0.6 # you can adjust this threshold for your own dataset\n","preds_test=(probs_test >= threshold).astype('uint8') # predicted labels using the above fixed threshold\n","\n","# metric = load_metric(\"glue\", \"mrpc\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"kr6OlCrxscMs","executionInfo":{"status":"ok","timestamp":1656625905964,"user_tz":240,"elapsed":158,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"34bd9ddb-d6dd-4453-b7d2-2f661441d508"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            0\n","0    0.991699\n","1    0.049866\n","2    0.057587\n","3    0.985352\n","4    0.039948\n","..        ...\n","403  0.036224\n","404  0.964355\n","405  0.992676\n","406  0.034241\n","407  0.803223\n","\n","[408 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-cb2f43dd-a534-4b2d-b7c7-b1152d15b7c9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.991699</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.049866</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.057587</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.985352</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.039948</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>0.036224</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>0.964355</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>0.992676</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>0.034241</td>\n","    </tr>\n","    <tr>\n","      <th>407</th>\n","      <td>0.803223</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>408 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb2f43dd-a534-4b2d-b7c7-b1152d15b7c9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cb2f43dd-a534-4b2d-b7c7-b1152d15b7c9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cb2f43dd-a534-4b2d-b7c7-b1152d15b7c9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":41}],"source":["pd.read_csv(path_to_output_file, header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PE0Uo_eSscMs","executionInfo":{"status":"ok","timestamp":1656625908789,"user_tz":240,"elapsed":224,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"9a04f4e8-4c1e-47ff-c1de-5d5e999110dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      1\n","1      0\n","2      0\n","3      1\n","4      0\n","      ..\n","403    0\n","404    1\n","405    1\n","406    0\n","407    1\n","Name: 0, Length: 408, dtype: uint8"]},"metadata":{},"execution_count":42}],"source":["preds_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z96KSM9YscMt"},"outputs":[],"source":["from sklearn.metrics import classification_report\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jh1snwVescMt","executionInfo":{"status":"ok","timestamp":1656625912451,"user_tz":240,"elapsed":197,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"6341c42c-9bdd-411f-b960-d769e9e339b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.79      0.80       129\n","           1       0.90      0.91      0.91       279\n","\n","    accuracy                           0.88       408\n","   macro avg       0.86      0.85      0.85       408\n","weighted avg       0.87      0.88      0.87       408\n","\n"]}],"source":["print(classification_report(labels_test,preds_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfPOFE8iscMt"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7n4ZD_JascMt","executionInfo":{"status":"ok","timestamp":1656625916098,"user_tz":240,"elapsed":229,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"d4cbc486-6979-463e-8a1b-396d8bb19d1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[102  27]\n"," [ 24 255]]\n"]}],"source":["print(confusion_matrix(labels_test, preds_test))"]},{"cell_type":"code","source":["import seaborn as sns\n","def show_confusion_matrix(confusion_matrix):\n","    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n","    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label');\n","\n","class_names=[0,1]\n","cm = confusion_matrix(labels_test,preds_test)\n","df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n","show_confusion_matrix(df_cm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"kXfvnmDun9BP","executionInfo":{"status":"ok","timestamp":1656626467821,"user_tz":240,"elapsed":587,"user":{"displayName":"Di Zhen","userId":"09127853115016959956"}},"outputId":"1d6a8355-7614-460a-be7a-832d6b605cc8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWsAAAEICAYAAACZJtWMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZdElEQVR4nO3debxVZd338c/3HDWRgwoKiCOgoKJ3oi+c8E5NS0XrQU0N9U4re9BScchCqzusHp/0zjnLwuFRb8MpBzBNVNQccmLKATS9BRNkEDBGM5Hf88deB7fEOWefw9nDddb37Wu92Ptaa6/1O77gy8W1r3UtRQRmZlbb6qpdgJmZtcxhbWaWAIe1mVkCHNZmZglwWJuZJcBhbWaWgPWqXUCxu6a+63mE9ilHDOhV7RKsBm20gbSu5+i0+xkl580HU65Z5+utK/eszSyfVFf61tKppG0kPS5pmqRXJZ2VtV8oabakqdl2eNFnLpD0pqTXJR3a0jVqqmdtZlYx6945L7YS+G5ETJbUBZgk6ZFs3xURcemnL60BwDBgF2BL4FFJ/SPi46Yu4LA2s3yqq2+3U0XEHGBO9nqppOnAVs18ZChwe0R8CMyQ9CawF/Bsk+W2W7VmZilpxTCIpOGSJhZtw5s8rdQb2B14Pms6Q9JLkm6U1DVr2wp4p+hjs2g+3B3WZpZTUslbRIyOiEFF2+i1n1INwN3A2RGxBLgW2B4YSKHnfVlby/UwiJnlUwlfHLbqdNL6FIL6dxFxD0BEzCvafx3wh+ztbGCboo9vnbU1yT1rM8unVvSsWz6VBNwATI+Iy4vai+eeHgW8kr0eBwyT9BlJfYB+wAvNXcM9azPLp/btWe8HfA14WdLUrO0HwPGSBgIBzAROBYiIVyXdCUyjMJPk9OZmgoDD2szyqn1ngzwNrK0L/mAzn7kIuKjUaziszSyf2needdk5rM0sn9r5C8Zyc1ibWT45rM3MElDnYRAzs9rXjl8wVoLD2szyycMgZmYJ8GwQM7MEuGdtZpYA96zNzBLgnrWZWQI8G8TMLAEeBjEzS4CHQczMEuCwNjNLgIdBzMwS4C8YzcwS4GEQM7MEeBjEzKz2yWFtZlb7HNZmZilIK6sd1maWT3V1/oLRzKzmeRjEzCwBDmszsxSkldUOazPLJ/eszcwS4LA2M0uAZ4OYmaUgrY61w9rM8snDIGZmCXBYm5klwGFtZpYA1TmszcxqnnvWZmYJcFibmSXAYW1mloK0stphbWb5lFrPOq37Lc3M2kldXV3JW0skbSPpcUnTJL0q6aysvZukRyS9kf3aNWuXpKslvSnpJUl7tFjvOv/EZmYpUiu2lq0EvhsRA4B9gNMlDQDOByZERD9gQvYeYAjQL9uGA9e2dIGyDoNIOgy4CqgHro+Ii8t5vVTcc+0lvD75OTpvvCkjLvt/AKxYtoQ7rvwpf39vLpt234JhZ4+iU0MXpj71CE+Nux0i2KDTRvyvU86mV+8dqvwTWLnNnTuH//zBSBYuXIgkvnLMcZzwHycx8rxzmDlzBgBLly6hS5eNueP391W52jS15zBIRMwB5mSvl0qaDmwFDAUOzA67GXgCGJm13xIRATwnaVNJvbLzrFXZwlpSPfAr4IvALOBFSeMiYlq5rpmK3Q84jH0OPYrf/+rnq9uevG8MfXfdgwOOPIE/3TeGJ8eO4dATT6Vbj158a9SVdGrowl+nPM/Y6y7jtIta/EvYEldfX8+5541k5wG7sHz5Mk746lfYe9/BXHLpFauPuewXF9PQ0KWKVaatNWEtaTiFHnCj0RExuoljewO7A88DPYsCeC7QM3u9FfBO0cdmZW1NhnU5h0H2At6MiLci4p/A7RT+Nsm9PgN2o1PDxp9qe23in9njgEMB2OOAQ5n+4jMAbLvjrnTK/kBu028AixcuqGyxVhXdu/dg5wG7ANC5cwN9+mzPe/Pmrd4fETwy/iEOO/yIapWYPEklbxExOiIGFW1NBXUDcDdwdkQsKd6X9aKjrfWWM6yb+pvD1mLZ4kV06boZAA2bdmPZ4kX/csykxx+k/8C9Kl2aVdm7s2fx+mvT2fWzu61umzxpIt0224zttutdvcIS15qwLvF861MI6t9FxD1Z8zxJvbL9vYD5WftsYJuij2+dtTWp6l8wShouaaKkiY/efWu1y6kJkmCN3yBvvTKFSY89yKEnDm/iU9YRrVixnPPOGcF5Iy+goaFhdftDf3zAvep1pDqVvLV4rkKi3wBMj4jLi3aNA07OXp8MjC1qPymbFbIPsLi58Woo7xeMJf3Nkf1zYjTAXVPfbfM/EVLXsEk3lr6/kC5dN2Pp+wtp2Ljr6n1z3/4f7h19KSeffzEbddmkilVaJX300Uecd84IhhzxZQ7+wiGr21euXMljjz7CmDvurmJ16Wvnedb7AV8DXpY0NWv7AXAxcKekU4C3geOyfQ8ChwNvAiuAb7R0gXKG9YtAP0l9KIT0MOCEMl4vaTsNGszkP43ngCNPYPKfxrPToMEA/H3BPMZc9mOOPf0CNt9ymxbOYh1FRPCTUT+iT9/t+drJn/5z/Pxzz9K7Tx96brFFlarrGNozqyPiaZqe5HfwWo4P4PTWXKNsYR0RKyWdAYynMHXvxoh4tVzXS8kdV/2MGdOmsmLpYv7r28dy0LFfZ/+hx3P7lT9h8uMPssnmPRl2zigAHv/9LaxYtoRxN1wJQF19Pd/5+W+rWb5VwNQpk3ng/rH069efrx5zJABnjDiHz+1/AOP/+ACHHf6lKleYvtTuYFQh4GtDnodBbO2OGNCr2iVYDdpog3VP2v7ff6jkvPnrfx1W9WT32iBmlkt1fviAmVntc1ibmSUgsSFrh7WZ5VNqXzA6rM0slxLLaoe1meWTe9ZmZgnwF4xmZglwz9rMLAGJZbXD2szyyT1rM7MEJJbVDmszyyf3rM3MEuDZIGZmCUisY+2wNrN88jCImVkCEstqh7WZ5ZN71mZmCfAXjGZmCXDP2swsAYlltcPazPLJPWszswQkltUOazPLJ/eszcwSUO/ZIGZmtS+xjrXD2szyycMgZmYJSGwUpOmwlvRLIJraHxEjylKRmVkFdKSe9cSKVWFmVmF1HSWsI+Lm4veSNoqIFeUvycys/FIbBqlr6QBJ+0qaBryWvd9N0q/LXpmZWRlJKnmrBS2GNXAlcCiwECAi/gLsX86izMzKTSp9qwUlzQaJiHfW+Nvl4/KUY2ZWGR1mzLrIO5IGAyFpfeAsYHp5yzIzK6/EsrqksD4NuArYCngXGA+cXs6izMzKrcM9fCAiFgAnVqAWM7OKSW0YpJTZIH0l3S/pPUnzJY2V1LcSxZmZlYtasbV4LunGLB9fKWq7UNJsSVOz7fCifRdIelPS65IOLaXeUmaDjAHuBHoBWwJ3AbeVcnIzs1rVzlP3bgIOW0v7FRExMNsezK47ABgG7JJ95teS6lu6QClhvVFE/HdErMy2W4ENS6nezKxW1an0rSUR8SSwqMRLDwVuj4gPI2IG8CawV4v1NrVDUjdJ3YA/SjpfUm9J20n6PvBgiUWZmdWk1vSsJQ2XNLFoG17iZc6Q9FI2TNI1a9sKeKfomFlZW7Oa+4JxEoWFnBr/Xjm1aF8AF5RYrJlZzWnNbJCIGA2MbuUlrgV+RiEvfwZcBnyzledYrbm1Qfq09aRmZrWu3DP3ImJe42tJ1wF/yN7OBrYpOnTrrK1ZJd3BKGlXYABFY9URcUspnzUzq0XlXvNDUq+ImJO9PQponCkyDhgj6XIKkzb6AS+0dL4Ww1rSKOBACmH9IDAEeBpwWJtZstozqiXdRiEnN5c0CxgFHChpIIVhkJlkQ8kR8aqkO4FpwErg9IhocQmPUnrWxwC7AVMi4huSegK3tv7HMTOrHe15U0xEHL+W5huaOf4i4KLWXKOUsP4gIlZJWilpY2A+nx5vMTNLToe73RyYKGlT4DoKM0SWAc+WtSozszJL7G7zktYG+U728jeSHgI2joiXyluWmVl5pbY2SHMPzN2juX0RMbk8JZmZlV9iWd1sz/qyZvYFcFA718KXd92yvU9pieu65xnVLsFq0AdTrlnnc9TK47pK1dxNMZ+vZCFmZpVUysJItaSkm2LMzDqa+g44G8TMrMNJLKsd1maWT6mNWZfypBhJ+g9JP87ebyupxbVXzcxqWXuuZ10JpYyx/xrYF2i8nXIp8KuyVWRmVgFS6VstKGUYZO+I2EPSFICIeF/SBmWuy8ysrDrMTTFFPsqeDxYAkroDq8palZlZmdWnldUlhfXVwL1AD0kXUViF70dlrcrMrMw6XM86In4naRJwMIUlYI+MiOllr8zMrIwSy+qSHj6wLbACuL+4LSL+Vs7CzMzKqVZmeZSqlGGQB/jkwbkbAn2A14FdyliXmVlZdcRhkH8rfp+txvedJg43M0tCfWKLg7T6DsaImCxp73IUY2ZWKWrXpzCWXylj1ucWva0D9gDeLVtFZmYV0BHHrLsUvV5JYQz77vKUY2ZWGR0qrLObYbpExHkVqsfMrCJSW8ipucd6rRcRKyXtV8mCzMwqoSP1rF+gMD49VdI44C5geePOiLinzLWZmZVNR3z4wIbAQgrPXGycbx2Aw9rMkpVYVjcb1j2ymSCv8ElIN4qyVmVmVmaJDVk3G9b1QAOsdTKiw9rMklbXgeZZz4mIn1asEjOzCupIPevEfhQzs9J1pDHrgytWhZlZhXWY2SARsaiShZiZVVKHW3XPzKwjSiyrHdZmlk+JrZDqsDazfOowa4OYmXVk9Q5rM7Pal1ZUO6zNLKcS61g7rM0sn1Ibs07tC1Ezs3ZR14qtJZJulDRf0itFbd0kPSLpjezXrlm7JF0t6U1JL2UPIS+pXjOz3JFU8laCm4DD1mg7H5gQEf2ACdl7gCFAv2wbDlxbygUc1maWS3VSyVtLIuJJYM27vocCN2evbwaOLGq/JQqeAzaV1KvFekv+yczMOpDWDINIGi5pYtE2vIRL9IyIOdnruUDP7PVWwDtFx83K2prlLxjNLJda8wVjRIwGRrf1WhERktbpOQDuWZtZLqkVWxvNaxzeyH6dn7XPBrYpOm7rrK1ZDmszyyWp9K2NxgEnZ69PBsYWtZ+UzQrZB1hcNFzSJA+DmFkutedjvSTdBhwIbC5pFjAKuBi4U9IpwNvAcdnhDwKHA28CK4BvlHINh7WZ5VJ7rmcdEcc3setfHuISEQGc3tprOKzNLJcSu4HRYW1m+dSRnm5uZtZhuWdtZpYAh7WZWQL88AEzswTIY9ZmZrUvsY51+cJa0o3Al4D5EbFrua6Turlz5vDDC77PooULQeKYY4/jxK+dvHr/zTfdyOW/uIQnnn6Wrl27VbFSK7ete27K9T87iR6bdSECbrz7GX512xP88NTD+ebRg3nv/WUAjLpmHOOfnsa2vbox9Z4f8de3C3cxv/DyTEZcdHs1f4SkuGf9iZuAa4BbyniN5NWvV8953z+fnQfswvLlyxh27FfYZ9/92H6HHZg7Zw7PPvMMvXptWe0yrQJWfryK8y+/h6mvzaJho8/w5zEjmfD8awD88tbHufK/J/zLZ96atYB9hl1c6VI7hLq0srp8a4M0sb6rraF79x7sPGAXADp3bqBv377Mnz8PgF9c8nPO+e73knv8kLXN3AVLmPraLACWrfiQ12bMZcvum1a5qo5LrfivFnghpxoye/YsXps+nX/77G48/tij9OjZgx132qnaZVkVbNurGwN33JoXX5kJwGnD9ueFOy7gN6NOZNMunVYf13urzXj2tpE8fP1Z7Lf79lWqNk11Kn2rBQ7rGrFi+XK+e/YIvnf+D6ivr+f60b/lO2ecVe2yrAo6d9qA2y79Ft+79G6WLv8H1931FAO+fCF7D7uYuQuWcPG5RwOFnnj/IT9m3+MvYeRl93DT//06XTpvWOXq09GeT4qphKqHdfETGG64rs1reyfto48+4tyzR3D4EV/mC188hFnv/I3Zs2dx3NFDGfLFg5g3by7DjjmaBe+9V+1SrczWW6+O2y7939zxx4mMfewvAMxftJRVq4KI4MZ7nmHQrtsB8M+PVrJo8XIApkx/h7dmLaDfdj2qVntqKrCedbuq+tS94icw/GMl6/QkhRRFBBf++If07duXk75eWCmxX/8deeKpZ1cfM+SLBzHmzt97NkgO/GbUibw+Yy5X3/rY6rYtNt+YuQuWADD0oN2Y9j+FpY8379rAosXLWbUq6L3VZuywbXdmzFpQlbqTVCspXKJyTt37l/VdI+KGcl0vVVMmT+IP48bSr39/jjt6KABnnn0un9v/gCpXZpU2eGBfTvzS3rz819k8d3vhQdijrhnHcYcO4rM7bk1E8PacRZz5f24D4N/32IH//PYRfLTyY1atCs686HbeX7Kimj9CUmrli8NSqbC0am3IY8/amtd1zzOqXYLVoA+mXLPOSfviW4tLzps9+25S9WSv+jCImVlVVD1+W8dhbWa5lNowiMPazHKpRmbklcxhbWa5lFhWO6zNLKcSS2uHtZnlUq3cmVgqh7WZ5VJaUe2wNrO8SiytHdZmlkueumdmloDEhqwd1maWT4lltcPazPIptScwOazNLJcSy2qHtZnlU2JZ7bA2s5xKLK0d1maWS566Z2aWgFp5anmpHNZmlk8OazOz2udhEDOzBHjqnplZAhLLaoe1meVUYmntsDazXGrvhw9ImgksBT4GVkbEIEndgDuA3sBM4LiIeL8t569rnzLNzNKiVmyt8PmIGBgRg7L35wMTIqIfMCF73yYOazPLpzKl9RqGAjdnr28GjmzriRzWZpZLas1/0nBJE4u24Ws5ZQAPS5pUtL9nRMzJXs8Fera1Xo9Zm1kutWbIOiJGA6NbOOzfI2K2pB7AI5JeW+McISlaXWjGPWszy6X2HgWJiNnZr/OBe4G9gHmSegFkv85va70OazPLJUklbyWcq7OkLo2vgUOAV4BxwMnZYScDY9tar4dBzCyX2nnmXk/g3izY1wPGRMRDkl4E7pR0CvA2cFxbL+CwNrNcas+sjoi3gN3W0r4QOLg9ruGwNrNc8togZmYJ8Kp7ZmYJcM/azCwBDmszswR4GMTMLAVpZbXD2szyKbGsdlibWT55zNrMLAHt/fCBcvPaIGZmCXDP2sxyKbGOtcPazPLJU/fMzBLgnrWZWQISy2qHtZnlUykPFaglDmszy6XEstphbWb5lFhWO6zNLKcSS2uHtZnlUmpT9xQR1a7B1kLS8IgYXe06rHb490S++Xbz2jW82gVYzfHviRxzWJuZJcBhbWaWAId17fLYpK3JvydyzF8wmpklwD1rM7MEOKzNzBLgsK4iSb4pyT5Fqa0uZBXjsKiCLKQvBtaXdH9EPFrtmqz6JDV2nkJSXUSsqmpBVlPcs66wrOd0NdALeAEYKel0SZ+pbmVWTZK+AcwCflLtWqw2OawrrwswEDgtIn4HXAr0B46talVWNZIagKHAJcARknaIiFVFPW0zh3WlRcQSYCbw9azpGWAKMFjSFlUqy6ooIpYBIyLiKuBh4KdZu4dBbDWHdXXcCwyU1Cv7g/oy8CGFoRHLoYj4W/bySmAHSYcASKqvXlVWSxzW1fE0sICsdx0Rk4A9gU5VrMlqQETMBW4Afpi9/1jS+tWtymqBw7oKImIOMBYYIulYSb2BfwArq1mXVV82C+S3wHuSrpL0S2D3atdl1eewrpKI+DPwc2AI8BBwX0S8UN2qrNqyLxY3AnoAJwBv+PeFgdcGqbrsn7gREe5VGwCSzgO2BkZGxIfVrsdqg8ParMb4hhhbG4e1mVkCPGZtZpYAh7WZWQIc1mZmCXBY26dI+ljSVEmvSLorm0bW1nPdJOmY7PX1kgY0c+yBkga34RozJW1eavsaxyxr5bUuzGZqmFWcw9rW9EFEDIyIXYF/AqcV72zrGtwR8a2ImNbMIQcCrQ5rs7xwWFtznqKwTsWBkp6SNA6YJqle0i8kvSjpJUmnQmH5V0nXSHpd0qMUbuwg2/eEpEHZ68MkTZb0F0kTsjs4TwPOyXr1n5PUXdLd2TVelLRf9tnNJD0s6VVJ1wMtLtYv6T5Jk7LPDF9j3xVZ+wRJ3bO27SU9lH3mKUk7tcf/TLN14YcP2FplPejGuysB9gB2jYgZWeAtjog9s3W4n5H0MIXboncEBgA9gWnAjWuctztwHbB/dq5uEbFI0m+AZRFxaXbcGOCKiHha0rbAeGBnYBTwdET8VNIRwCkl/DjfzK7RCXhR0t0RsRDoDEyMiHMk/Tg79xkUniJ+WkS8IWlv4NfAQW3432jWbhzWtqZOkqZmr5+isKjQYOCFiJiRtR8CfLZxPBrYBOgH7A/cFhEfA+9Kemwt598HeLLxXBGxqIk6vgAMKHrK1cbZus/7A0dnn31A0vsl/EwjJB2Vvd4mq3UhsAq4I2u/Fbgnu8Zg4K6ia/vBEFZ1Dmtb0wcRMbC4IQut5cVNwJkRMX6N4w5vxzrqgH0i4h9rqaVkkg6kEPz7RsQKSU8AGzZxeGTX/fua/w/Mqs1j1tYW44FvNy7dKam/pM7Ak8BXszHtXsDn1/LZ54D9JfXJPtsta19K4Sk6jR4Gzmx8I6kxPJ+ksMARkoYAXVuodRPg/Syod6LQs29UBzT+6+AECsMrS4AZko7NriFJu7VwDbOyc1hbW1xPYTx6sqRXgN9S+FfavcAb2b5bgGfX/GBEvAcMpzDk8Bc+GYa4Hziq8QtGYAQwKPsCcxqfzEr5CYWwf5XCcMjfaN5DwHqSplN4SPFzRfuWA3tlP8NBZE9oAU4ETsnqe5XCI7fMqsprg5iZJcA9azOzBDiszcwS4LA2M0uAw9rMLAEOazOzBDiszcwS4LA2M0uAw9rMLAH/H60lbnoOabY4AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"colab":{"name":"sentence_similarity_based_on_ALBERT.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"742da9b0dd26490e91b27e234784c77a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68fc3aa37c38417e821e5e633a244ac3","IPY_MODEL_46e1dd1e01c641e59b545946d759885d","IPY_MODEL_f325bd1f03ca4545ac031c3f50370563"],"layout":"IPY_MODEL_1bc35f10619c430da108631f91bcdc8b"}},"68fc3aa37c38417e821e5e633a244ac3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03b2d1f0399342719faa298e7a500b47","placeholder":"​","style":"IPY_MODEL_3e0ffedca8f04bbd89f15372e98fb143","value":"100%"}},"46e1dd1e01c641e59b545946d759885d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1deb50f9dc244b578af5c507e9e769b9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e07731151324d09b4e36767b7e91de8","value":3}},"f325bd1f03ca4545ac031c3f50370563":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b25dfd2a3b34899908b3e4c1a6db450","placeholder":"​","style":"IPY_MODEL_212d3949b34d4429a38ea5d70d6179c7","value":" 3/3 [00:00&lt;00:00, 63.44it/s]"}},"1bc35f10619c430da108631f91bcdc8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03b2d1f0399342719faa298e7a500b47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e0ffedca8f04bbd89f15372e98fb143":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1deb50f9dc244b578af5c507e9e769b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e07731151324d09b4e36767b7e91de8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b25dfd2a3b34899908b3e4c1a6db450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"212d3949b34d4429a38ea5d70d6179c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}